PYTHONUNBUFFERED=1

DJANGO_ALLOWED_HOSTS=*
DEBUG=0

LOG_TO_FILE=True

SQL_ENGINE=django.db.backends.postgresql_psycopg2
SQL_DATABASE=c01_prod
SQL_USER=django
SQL_PASSWORD=c01_password
SQL_HOST=db
SQL_PORT=5432

POSTGRES_DB=c01_prod
POSTGRES_USER=django
POSTGRES_PASSWORD=c01_password

EXECUTION_TYPE=distributed

ZOOKEEPER_CLIENT_PORT=2181
ZOOKEEPER_HOSTS = "zookeeper:2181"

KAFKA_HOST=kafka
KAFKA_HOSTS="kafka:9092"
KAFKA_PORT=9092
KAFKA_BROKER_ID=1
KAFKA_ZOOKEEPER_CONNECT="zookeeper:2181"
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
KAFKA_ADVERTISED_HOST_NAME=kafka
KAFKA_ADVERTISED_PORT=9092
KAFKA_ADVERTISED_LISTENERS="PLAINTEXT://kafka:9092"
KAFKA_NUM_NETWORK_THREADS = 3
KAFKA_NUM_IO_THREADS = 8
KAFKA_NUM_RECOVERY_THREADS_PER_DATA = 1
KAFKA_SOCKET_SEND_BUFFER_BYTES = 102400
KAFKA_SOCKET_RECEIVE_BUFFER_BYTES = 102400
KAFKA_SOCKET_REQUEST_MAX_BYTES = 104857600
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR = 1
KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR = 1
KAFKA_TRANSACTION_STATE_LOG_MIN_ISR = 1
KAFKA_LOG_RETENTION_HOURS = 168
KAFKA_LOG_SEGMENT_BYTES = 1073741824
KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS = 300000
KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS = 6000
KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS = 0
KAFKA_GROUP_MIN_SESSION_TIMEOUT_MS = 60000
KAFKA_GROUP_MAX_SESSION_TIMEOUT_MS = 1200000

# KAFKA_CONTROLLER_SOCKET_TIMEOUT_MS = 600000
# KAFKA_OFFSETS_COMMIT_TIMEOUT_MS = 600000
# KAFKA_REQUEST_TIMEOUT_MS = 600000
# KAFKA_SOCKET_CONNECTION_SETUP_TIMEOUT_MS = 600000
# KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS = 600000
# KAFKA_ZOOKEEPER_SESSION_TIMEOUT_MS = 600000

# The following partition/replication factor values are just for testing
# and should be properly decided upon in the future (a replication factor
# > 1 requires more brokers)
# KAFKA_CREATE_TOPICS="file_description:1:1"

REDIS_HOST = "redis"
REDIS_PORT = "6379"

SERVER_ADDRESS = 'http://web:8000'
