import os

KAFKA_HOSTS = [x.strip() for x in os.getenv('KAFKA_HOSTS', 'localhost:9092').split(',')]
KAFKA_TOPIC_PREFIX = os.getenv('KAFKA_TOPIC_PREFIX', 'crawler_ufmg')

KAFKA_CONSUMER_AUTO_OFFSET_RESET = 'earliest'
KAFKA_CONSUMER_TIMEOUT = 120000
KAFKA_CONSUMER_COMMIT_INTERVAL_MS = 5000
KAFKA_CONSUMER_AUTO_COMMIT_ENABLE = True
KAFKA_CONSUMER_FETCH_MESSAGE_MAX_BYTES = 10 * 1024 * 1024  # 10MB
KAFKA_PRODUCER_BATCH_LINGER_MS = 25  # 25 ms before flush
KAFKA_PRODUCER_BUFFER_BYTES = 4 * 1024 * 1024  # 4MB before blocking
KAFKA_CONNECTIONS_MAX_IDLE_MS = 10 * 60 * 1000
KAFKA_REQUEST_TIMEOUT_MS = 5 * 60 * 1000
KAFKA_SESSION_TIMEOUT_MS = 2 * 60 * 1000

REQUEST_USER_AGENT = os.getenv(
    'REQUEST_USER_AGENT', 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36')
REQUEST_HEADERS = {'User-Agent': REQUEST_USER_AGENT}

CRAWLED_TOPIC = os.getenv('CRAWLED_TOPIC', KAFKA_TOPIC_PREFIX + '.scrapy_cluster.crawled_firehose')

WRITER_TOPIC = os.getenv('WRITER_TOPIC', KAFKA_TOPIC_PREFIX + '.writer')
FILE_DOWNLOADER_TOPIC = os.getenv('FILE_DOWNLOADER_TOPIC', KAFKA_TOPIC_PREFIX + '.file_downloader')
FILE_DESCRIPTOR_TOPIC = os.getenv('FILE_DESCRIPTOR_TOPIC', KAFKA_TOPIC_PREFIX + '.file_descriptor')

NUM_CRAWLED_DATA_CONSUMERS = os.getenv('NUM_CRAWLED_DATA_CONSUMERS', 4)
NUM_FILE_DOWNLOADER_CONSUMERS = os.getenv('NUM_FILE_DOWNLOADER_CONSUMERS', 4)
NUM_FILE_DESCRIPTOR_CONSUMERS = os.getenv('NUM_FILE_DESCRIPTOR_CONSUMERS', 4)

CRAWLED_DATA_CONSUMER_GROUP = os.getenv('CRAWLED_DATA_CONSUMER_DATA', KAFKA_TOPIC_PREFIX + '.crawled_data_group')
FILE_DOWNLOADER_CONSUMER_GROUP = os.getenv('FILE_DOWNLOADER_CONSUMER_GROUP', KAFKA_TOPIC_PREFIX + '.file_downloader_group')
FILE_DESCRIPTOR_CONSUMER_GROUP = os.getenv('FILE_DESCRIPTOR_CONSUMER_GROUP', KAFKA_TOPIC_PREFIX + '.file_descriptor_group')

OUTPUT_FOLDER = os.getenv('OUTPUT_FOLDER', '/home/elves/Desktop/data')